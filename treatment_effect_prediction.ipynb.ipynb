{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c452e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\02\\anaconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\02\\anaconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\02\\anaconda3\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c773444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ\n",
      "ğŸš€ ê°„ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™” (XAI í¬í•¨)\n",
      "ğŸ“ ë°ì´í„° ê²½ë¡œ: C:\\Users\\02\\Documents\\GDCdata_liver\\clinical_data_liver.csv\n",
      "â° ì‹œì‘ ì‹œê°„: 2025-06-13 15:55:23\n",
      "============================================================\n",
      "ğŸ¯ ê°„ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ì „ì²´ ë¶„ì„ ì‹œì‘ (XAI í¬í•¨)\n",
      "\n",
      "ğŸ“Š 1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰\n",
      "âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ: 377í–‰ Ã— 87ì—´\n",
      "ğŸ“ˆ ë°ì´í„° ê¸°ë³¸ ì •ë³´:\n",
      "   - ì´ í™˜ì ìˆ˜: 377\n",
      "   - ì´ ì»¬ëŸ¼ ìˆ˜: 87\n",
      "   - ìƒì¡´ í™˜ì: 245ëª…\n",
      "   - ì‚¬ë§ í™˜ì: 132ëª…\n",
      "   - ì‚¬ë§ë¥ : 35.0%\n",
      "\n",
      "ğŸ”§ 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
      "âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: 20ê°œ\n",
      "ğŸ”„ ìƒì¡´ ë³€ìˆ˜ ìƒì„± ì¤‘...\n",
      "âœ… ìœ íš¨í•œ ìƒì¡´ ë°ì´í„°: 372ëª…\n",
      "   - ì‚¬ë§ ì´ë²¤íŠ¸: 132ê±´\n",
      "   - ì¤‘ê°„ ìƒì¡´ ì‹œê°„: 602ì¼\n",
      "   - ì¹˜ë£Œ íš¨ê³¼ ì–‘í˜¸: 188ëª…\n",
      "\n",
      "ğŸ“‹ ê²°ì¸¡ê°’ ë¶„ì„:\n",
      "   - days_to_death: 240ê°œ (64.5%)\n",
      "   - child_pugh_classification: 47ê°œ (12.6%)\n",
      "   - ishak_fibrosis_score: 96ê°œ (25.8%)\n",
      "   - ajcc_pathologic_stage: 24ê°œ (6.5%)\n",
      "   - ajcc_pathologic_t: 2ê°œ (0.5%)\n",
      "   - ajcc_pathologic_n: 1ê°œ (0.3%)\n",
      "   - tumor_grade: 5ê°œ (1.3%)\n",
      "   - age_at_diagnosis: 3ê°œ (0.8%)\n",
      "   - treatments_pharmaceutical_treatment_intent_type: 44ê°œ (11.8%)\n",
      "   - treatments_pharmaceutical_treatment_type: 42ê°œ (11.3%)\n",
      "   - year_of_diagnosis: 2ê°œ (0.5%)\n",
      "\n",
      "ğŸ¯ 3. íŠ¹ì„± ì¤€ë¹„ ë° ì¸ì½”ë”©\n",
      "ğŸ“Š ì´ˆê¸° íŠ¹ì„± ê°œìˆ˜: 17\n",
      "ğŸ“Š ìƒ˜í”Œ ê°œìˆ˜: 372\n",
      "ğŸ”¤ ë²”ì£¼í˜• ë³€ìˆ˜: 15ê°œ\n",
      "ğŸ”¢ ìˆ˜ì¹˜í˜• ë³€ìˆ˜: 2ê°œ\n",
      "ğŸ”„ ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "   ğŸ” child_pugh_classification ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'A': 222, 'Unknown': 81, nan: 47}\n",
      "      - 'Unknown' ê°’ ìœ ì§€ (ì„ìƒì  ì˜ë¯¸ ìˆìŒ)\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'A'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” ishak_fibrosis_score ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {nan: 96, '0 - No Fibrosis': 76, '6 - Established Cirrhosis': 70}\n",
      "      - 'Unknown' ê°’ì„ ê²°ì¸¡ì¹˜ë¡œ ë³€í™˜ í›„ ëŒ€ì²´\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ '0 - No Fibrosis'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” ajcc_pathologic_stage ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'Stage I': 174, 'Stage II': 85, 'Stage IIIA': 63}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'Stage I'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” ajcc_pathologic_t ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'T1': 184, 'T2': 91, 'T3': 44}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'T1'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” ajcc_pathologic_n ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'N0': 254, 'NX': 113, 'N1': 4}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'N0'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” ajcc_pathologic_m ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'M0': 269, 'MX': 99, 'M1': 4}\n",
      "\n",
      "   ğŸ” tumor_grade ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'G2': 178, 'G3': 121, 'G1': 55}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'G2'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” morphology ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'8170/3': 355, '8180/3': 7, '8171/3': 4}\n",
      "\n",
      "   ğŸ” gender ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'male': 251, 'female': 121}\n",
      "\n",
      "   ğŸ” race ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'white': 186, 'asian': 158, 'black or african american': 17}\n",
      "      - 'Unknown' ê°’ì„ ê²°ì¸¡ì¹˜ë¡œ ë³€í™˜ í›„ ëŒ€ì²´\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'white'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” ethnicity ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'not hispanic or latino': 336, 'hispanic or latino': 18, 'not reported': 15}\n",
      "      - 'Unknown' ê°’ì„ ê²°ì¸¡ì¹˜ë¡œ ë³€í™˜ í›„ ëŒ€ì²´\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'not hispanic or latino'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” treatments_pharmaceutical_treatment_intent_type ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'Adjuvant': 328, nan: 44}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'Adjuvant'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” treatments_pharmaceutical_treatment_type ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'Pharmaceutical Therapy, NOS': 330, nan: 42}\n",
      "      - ê²°ì¸¡ì¹˜ë¥¼ 'Pharmaceutical Therapy, NOS'ë¡œ ëŒ€ì²´\n",
      "\n",
      "   ğŸ” prior_treatment ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'No': 370, 'Yes': 2}\n",
      "\n",
      "   ğŸ” primary_diagnosis ì²˜ë¦¬:\n",
      "      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {'Hepatocellular carcinoma, NOS': 355, 'Combined hepatocellular carcinoma and cholangiocarcinoma': 7, 'Hepatocellular carcinoma, fibrolamellar': 4}\n",
      "\n",
      "ğŸ”„ ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©:\n",
      "   - child_pugh_classification ì¸ì½”ë”© ë§¤í•‘: {'A': 0, 'B': 1, 'C': 2, 'Unknown': 3}\n",
      "   - ajcc_pathologic_stage ì¸ì½”ë”© ë§¤í•‘: {'Stage I': 0, 'Stage II': 1, 'Stage III': 2, 'Stage IIIA': 3, 'Stage IIIB': 4, 'Stage IIIC': 5, 'Stage IV': 6, 'Stage IVA': 7, 'Stage IVB': 8}\n",
      "   - ajcc_pathologic_t ì¸ì½”ë”© ë§¤í•‘: {'T1': 0, 'T2': 1, 'T2a': 2, 'T2b': 3, 'T3': 4, 'T3a': 5, 'T3b': 6, 'T4': 7, 'TX': 8}\n",
      "   - ajcc_pathologic_n ì¸ì½”ë”© ë§¤í•‘: {'N0': 0, 'N1': 1, 'NX': 2}\n",
      "   - ajcc_pathologic_m ì¸ì½”ë”© ë§¤í•‘: {'M0': 0, 'M1': 1, 'MX': 2}\n",
      "   - tumor_grade ì¸ì½”ë”© ë§¤í•‘: {'G1': 0, 'G2': 1, 'G3': 2, 'G4': 3}\n",
      "   - treatments_pharmaceutical_treatment_intent_type ì¸ì½”ë”© ë§¤í•‘: {'Adjuvant': 0}\n",
      "   - treatments_pharmaceutical_treatment_type ì¸ì½”ë”© ë§¤í•‘: {'Pharmaceutical Therapy, NOS': 0}\n",
      "   - prior_treatment ì¸ì½”ë”© ë§¤í•‘: {'No': 0, 'Yes': 1}\n",
      "âœ… íŠ¹ì„± ì¤€ë¹„ ì™„ë£Œ\n",
      "\n",
      "âœ‚ï¸  4. ë°ì´í„° ë¶„í•  (í›ˆë ¨:ê²€ì¦:í…ŒìŠ¤íŠ¸ = 60:20:20)\n",
      "ğŸ“Š í›ˆë ¨ ì„¸íŠ¸: 222ëª… (ì‚¬ë§: 79ëª…, ì¹˜ë£Œíš¨ê³¼ì–‘í˜¸: 112ëª…)\n",
      "ğŸ“Š ê²€ì¦ ì„¸íŠ¸: 75ëª… (ì‚¬ë§: 25ëª…, ì¹˜ë£Œíš¨ê³¼ì–‘í˜¸: 38ëª…)\n",
      "ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: 75ëª… (ì‚¬ë§: 28ëª…, ì¹˜ë£Œíš¨ê³¼ì–‘í˜¸: 38ëª…)\n",
      "\n",
      "ğŸ¤– 5. ëª¨ë¸ í›ˆë ¨\n",
      "ğŸ”„ Random Survival Forest í›ˆë ¨ ì¤‘...\n",
      "âœ… Random Survival Forest í›ˆë ¨ ì™„ë£Œ\n",
      "ğŸ”„ Cox ë¹„ë¡€ìœ„í—˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "âœ… Cox ìƒì¡´ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\n",
      "ğŸ”„ Gradient Boosting Survival Analysis í›ˆë ¨ ì¤‘...\n",
      "âœ… Gradient Boosting Survival Analysis í›ˆë ¨ ì™„ë£Œ\n",
      "ğŸ”„ Random Forest ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "âœ… Random Forest ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\n",
      "ğŸ”„ XGBoost ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "âœ… XGBoost ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\n",
      "ğŸ”„ LightGBM ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "âœ… LightGBM ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\n",
      "ğŸ”„ Random Forest ìƒì¡´ ì‹œê°„ íšŒê·€ ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "âœ… Random Forest ìƒì¡´ ì‹œê°„ íšŒê·€ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\n",
      "\n",
      "ğŸ¯ ì´ 7ê°œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\n",
      "\n",
      "ğŸ“ˆ 6. ëª¨ë¸ í‰ê°€\n",
      "\n",
      "ğŸ” RSF ëª¨ë¸ í‰ê°€:\n",
      "   Train: C-index = 0.806\n",
      "   Validation: C-index = 0.661\n",
      "   Test: C-index = 0.603\n",
      "\n",
      "ğŸ” Cox_Survival ëª¨ë¸ í‰ê°€:\n",
      "   Train: C-index = 0.678\n",
      "   Validation: C-index = 0.630\n",
      "   Test: C-index = 0.648\n",
      "\n",
      "ğŸ” GBSA ëª¨ë¸ í‰ê°€:\n",
      "   Train: C-index = 0.824\n",
      "   Validation: C-index = 0.670\n",
      "   Test: C-index = 0.567\n",
      "\n",
      "ğŸ” RF_Treatment ëª¨ë¸ í‰ê°€:\n",
      "   Train: Accuracy = 0.995, AUC = 1.000\n",
      "   Validation: Accuracy = 0.720, AUC = 0.725\n",
      "   Test: Accuracy = 0.627, AUC = 0.708\n",
      "\n",
      "ğŸ” XGB_Treatment ëª¨ë¸ í‰ê°€:\n",
      "   Train: Accuracy = 0.995, AUC = 1.000\n",
      "   Validation: Accuracy = 0.653, AUC = 0.723\n",
      "   Test: Accuracy = 0.667, AUC = 0.681\n",
      "\n",
      "ğŸ” LGB_Treatment ëª¨ë¸ í‰ê°€:\n",
      "   Train: Accuracy = 0.955, AUC = 0.988\n",
      "   Validation: Accuracy = 0.667, AUC = 0.710\n",
      "   Test: Accuracy = 0.640, AUC = 0.703\n",
      "\n",
      "ğŸ” RF_Duration ëª¨ë¸ í‰ê°€:\n",
      "   Train: MSE = 68114, RÂ² = 0.880\n",
      "   Validation: MSE = 394885, RÂ² = 0.067\n",
      "   Test: MSE = 458548, RÂ² = 0.114\n",
      "\n",
      "ğŸ” XAI ëª¨ë¸ ì„¤ëª… ìƒì„±\n",
      "ğŸ”„ SHAP ì„¤ëª… ìƒì„± ì¤‘...\n",
      "âœ… RF_Treatment SHAP ì„¤ëª… ìƒì„± ì™„ë£Œ\n",
      "âœ… XGB_Treatment SHAP ì„¤ëª… ìƒì„± ì™„ë£Œ\n",
      "âœ… LGB_Treatment SHAP ì„¤ëª… ìƒì„± ì™„ë£Œ\n",
      "âœ… RF_Duration SHAP ì„¤ëª… ìƒì„± ì™„ë£Œ\n",
      "\n",
      "ğŸ”„ LIME ì„¤ëª… ìƒì„± ì¤‘...\n",
      "âœ… RF_Treatment LIME ì„¤ëª…ê¸° ìƒì„± ì™„ë£Œ\n",
      "âœ… XGB_Treatment LIME ì„¤ëª…ê¸° ìƒì„± ì™„ë£Œ\n",
      "âœ… LGB_Treatment LIME ì„¤ëª…ê¸° ìƒì„± ì™„ë£Œ\n",
      "\n",
      "ğŸ“Š XAI ì‹œê°í™” ìƒì„±\n",
      "ğŸ”„ RF_Treatment SHAP ì‹œê°í™” ë””ë²„ê¹…:\n",
      "   - SHAP ê°’ íƒ€ì…: <class 'numpy.ndarray'>\n",
      "   - SHAP ê°’ í˜•íƒœ: (50, 17, 2)\n",
      "   - 3ì°¨ì› ë°°ì—´ ê°ì§€: ì–‘ì„± í´ë˜ìŠ¤ ì„ íƒ\n",
      "   - ìµœì¢… SHAP í˜•íƒœ: (50, 17)\n",
      "   - ê¸°ëŒ“ê°’: 0.5046396396396399\n",
      "   - ê°œë³„ SHAP í˜•íƒœ: (17,)\n",
      "   - ê¸°ëŒ“ê°’ (ìŠ¤ì¹¼ë¼): 0.5046396396396399\n",
      "âœ… RF_Treatment SHAP ì‹œê°í™” ì™„ë£Œ\n",
      "ğŸ”„ XGB_Treatment SHAP ì‹œê°í™” ë””ë²„ê¹…:\n",
      "   - SHAP ê°’ íƒ€ì…: <class 'numpy.ndarray'>\n",
      "   - SHAP ê°’ í˜•íƒœ: (50, 17)\n",
      "   - 2ì°¨ì› ë°°ì—´ ì‚¬ìš©\n",
      "   - ìµœì¢… SHAP í˜•íƒœ: (50, 17)\n",
      "   - ê¸°ëŒ“ê°’: 0.02020314522087574\n",
      "   - ê°œë³„ SHAP í˜•íƒœ: (17,)\n",
      "   - ê¸°ëŒ“ê°’ (ìŠ¤ì¹¼ë¼): 0.02020314522087574\n",
      "âœ… XGB_Treatment SHAP ì‹œê°í™” ì™„ë£Œ\n",
      "ğŸ”„ LGB_Treatment SHAP ì‹œê°í™” ë””ë²„ê¹…:\n",
      "   - SHAP ê°’ íƒ€ì…: <class 'numpy.ndarray'>\n",
      "   - SHAP ê°’ í˜•íƒœ: (50, 17)\n",
      "   - 2ì°¨ì› ë°°ì—´ ì‚¬ìš©\n",
      "   - ìµœì¢… SHAP í˜•íƒœ: (50, 17)\n",
      "   - ê¸°ëŒ“ê°’: -0.14749655972085152\n",
      "   - ê°œë³„ SHAP í˜•íƒœ: (17,)\n",
      "   - ê¸°ëŒ“ê°’ (ìŠ¤ì¹¼ë¼): -0.14749655972085152\n",
      "âœ… LGB_Treatment SHAP ì‹œê°í™” ì™„ë£Œ\n",
      "ğŸ”„ RF_Duration SHAP ì‹œê°í™” ë””ë²„ê¹…:\n",
      "   - SHAP ê°’ íƒ€ì…: <class 'numpy.ndarray'>\n",
      "   - SHAP ê°’ í˜•íƒœ: (50, 17)\n",
      "   - 2ì°¨ì› ë°°ì—´ ì‚¬ìš©\n",
      "   - ìµœì¢… SHAP í˜•íƒœ: (50, 17)\n",
      "   - ê¸°ëŒ“ê°’: 826.6525225225226\n",
      "   - ê°œë³„ SHAP í˜•íƒœ: (17,)\n",
      "   - ê¸°ëŒ“ê°’ (ìŠ¤ì¹¼ë¼): 826.6525225225226\n",
      "âœ… RF_Duration SHAP ì‹œê°í™” ì™„ë£Œ\n",
      "âœ… RF_Treatment LIME ì‹œê°í™” ì™„ë£Œ\n",
      "âœ… XGB_Treatment LIME ì‹œê°í™” ì™„ë£Œ\n",
      "âœ… LGB_Treatment LIME ì‹œê°í™” ì™„ë£Œ\n",
      "\n",
      "ğŸ“Š 7. ê²°ê³¼ ì‹œê°í™”\n",
      "ğŸ” ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ ê³¡ì„  ìƒì„± ì¤‘...\n",
      "ğŸ“ ì‹œê°í™” ê²°ê³¼ ì €ì¥: liver_cancer_treatment_effect_prediction_with_xai.png\n",
      "\n",
      "ğŸ“‹ 8. ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±\n",
      "ğŸ“ ë³´ê³ ì„œ ì €ì¥: liver_cancer_treatment_effect_prediction_report.txt\n",
      "\n",
      "============================================================\n",
      "ê°„ì•” í™˜ì ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ë¶„ì„ ê²°ê³¼\n",
      "============================================================\n",
      "ë¶„ì„ ì¼ì‹œ: 2025-06-13 15:55:31\n",
      "ë°ì´í„° ê²½ë¡œ: C:\\Users\\02\\Documents\\GDCdata_liver\\clinical_data_liver.csv\n",
      "\n",
      "ğŸ“Š ë°ì´í„° ìš”ì•½\n",
      "------------------------------\n",
      "ì´ í™˜ì ìˆ˜: 372\n",
      "ì‚¬ë§ í™˜ì ìˆ˜: 132\n",
      "ì‚¬ë§ë¥ : 35.5%\n",
      "ì¤‘ê°„ ìƒì¡´ ì‹œê°„: 602ì¼\n",
      "ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸ í™˜ì: 188ëª…\n",
      "ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸ìœ¨: 50.5%\n",
      "ì‚¬ìš©ëœ íŠ¹ì„± ìˆ˜: 17\n",
      "\n",
      "ğŸ¤– ëª¨ë¸ ì„±ëŠ¥\n",
      "------------------------------\n",
      "\n",
      "ìƒì¡´ ì˜ˆì¸¡ ëª¨ë¸ (C-index):\n",
      "  RSF Train: C-index = 0.806\n",
      "  RSF Validation: C-index = 0.661\n",
      "  RSF Test: C-index = 0.603\n",
      "  Cox_Survival Train: C-index = 0.678\n",
      "  Cox_Survival Validation: C-index = 0.630\n",
      "  Cox_Survival Test: C-index = 0.648\n",
      "  GBSA Train: C-index = 0.824\n",
      "  GBSA Validation: C-index = 0.670\n",
      "  GBSA Test: C-index = 0.567\n",
      "\n",
      "ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ (Accuracy):\n",
      "  RF_Treatment Train: Accuracy = 0.995\n",
      "  RF_Treatment Validation: Accuracy = 0.720\n",
      "  RF_Treatment Test: Accuracy = 0.627\n",
      "  XGB_Treatment Train: Accuracy = 0.995\n",
      "  XGB_Treatment Validation: Accuracy = 0.653\n",
      "  XGB_Treatment Test: Accuracy = 0.667\n",
      "  LGB_Treatment Train: Accuracy = 0.955\n",
      "  LGB_Treatment Validation: Accuracy = 0.667\n",
      "  LGB_Treatment Test: Accuracy = 0.640\n",
      "\n",
      "ìƒì¡´ì‹œê°„ ì˜ˆì¸¡ ëª¨ë¸ (RÂ²):\n",
      "  RF_Duration Train: RÂ² = 0.880\n",
      "  RF_Duration Validation: RÂ² = 0.067\n",
      "  RF_Duration Test: RÂ² = 0.114\n",
      "\n",
      "ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: XGB_Treatment_Accuracy (ì ìˆ˜: 0.667)\n",
      "\n",
      "â„¹ï¸  ì‚¬ìš©ëœ ëª¨ë¸:\n",
      "   ìƒì¡´ ì˜ˆì¸¡: Random Survival Forest, Cox, GBSA\n",
      "   ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜: Random Forest, XGBoost, LightGBM\n",
      "   ìƒì¡´ì‹œê°„ ì˜ˆì¸¡: Random Forest Regressor\n",
      "   XAI: SHAP, LIME ì ìš©\n",
      "\n",
      "============================================================\n",
      "\n",
      "ğŸ’¾ 9. ëª¨ë¸ ì €ì¥\n",
      "âœ… RSF ëª¨ë¸ ì €ì¥: liver_cancer_treatment_rsf_model.pkl\n",
      "âœ… Cox_Survival ëª¨ë¸ ì €ì¥: liver_cancer_treatment_cox_survival_model.pkl\n",
      "âœ… GBSA ëª¨ë¸ ì €ì¥: liver_cancer_treatment_gbsa_model.pkl\n",
      "âœ… RF_Treatment ëª¨ë¸ ì €ì¥: liver_cancer_treatment_rf_treatment_model.pkl\n",
      "âœ… XGB_Treatment ëª¨ë¸ ì €ì¥: liver_cancer_treatment_xgb_treatment_model.pkl\n",
      "âœ… LGB_Treatment ëª¨ë¸ ì €ì¥: liver_cancer_treatment_lgb_treatment_model.pkl\n",
      "âœ… RF_Duration ëª¨ë¸ ì €ì¥: liver_cancer_treatment_rf_duration_model.pkl\n",
      "\n",
      "ğŸ‰ ì „ì²´ ë¶„ì„ ì™„ë£Œ!\n",
      "â° ì™„ë£Œ ì‹œê°„: 2025-06-13 15:55:31\n",
      "\n",
      "âœ¨ ëª¨ë“  ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:\n",
      "   - liver_cancer_treatment_effect_prediction_with_xai.png (ì‹œê°í™” ê²°ê³¼)\n",
      "   - liver_cancer_treatment_effect_prediction_report.txt (ë¶„ì„ ë³´ê³ ì„œ)\n",
      "   - liver_cancer_treatment_*_model.pkl (í›ˆë ¨ëœ ëª¨ë¸ë“¤)\n",
      "   - shap_*.png (SHAP ì„¤ëª…)\n",
      "   - lime_*.png (LIME ì„¤ëª…)\n",
      "\n",
      "ğŸ”¬ í¬í•¨ëœ ëª¨ë¸ë“¤:\n",
      "   ìƒì¡´ ì˜ˆì¸¡: Random Survival Forest, Cox, GBSA\n",
      "   ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜: Random Forest, XGBoost, LightGBM\n",
      "   ìƒì¡´ì‹œê°„ ì˜ˆì¸¡: Random Forest Regressor\n",
      "   XAI: SHAP, LIME ì ìš©\n",
      "\n",
      "ğŸ¯ ì„ìƒ í™œìš©:\n",
      "   - ê°œë³„í™”ëœ ì¹˜ë£Œ ê³„íš ìˆ˜ë¦½\n",
      "   - ì¹˜ë£Œ ë°˜ì‘ ì˜ˆì¸¡ ë° ëª¨ë‹ˆí„°ë§\n",
      "   - ê³ ìœ„í—˜êµ° ì§‘ì¤‘ ê´€ë¦¬ ì „ëµ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shap\n",
    "from lime import lime_tabular\n",
    "\n",
    "# ìƒì¡´ ë¶„ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "\n",
    "# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "def setup_korean_font():\n",
    "    \"\"\"í•œê¸€ í°íŠ¸ ì„¤ì •\"\"\"\n",
    "    import platform\n",
    "    import matplotlib.font_manager as fm\n",
    "    \n",
    "    system = platform.system()\n",
    "    \n",
    "    if system == 'Windows':\n",
    "        try:\n",
    "            plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "        except:\n",
    "            try:\n",
    "                font_path = 'C:/Windows/Fonts/malgun.ttf'\n",
    "                font_name = fm.FontProperties(fname=font_path).get_name()\n",
    "                plt.rc('font', family=font_name)\n",
    "            except:\n",
    "                print(\"âš ï¸ í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤íŒ¨\")\n",
    "    elif system == 'Darwin':\n",
    "        plt.rcParams['font.family'] = 'AppleGothic'\n",
    "    else:\n",
    "        plt.rcParams['font.family'] = 'NanumGothic'\n",
    "    \n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    print(\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ\")\n",
    "\n",
    "class LiverCancerTreatmentEffectPredictor:\n",
    "    \"\"\"ê°„ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ í´ë˜ìŠ¤ (XAI í¬í•¨)\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        setup_korean_font()\n",
    "        self.data_path = data_path\n",
    "        self.df = None\n",
    "        self.processed_df = None\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        self.feature_names = []\n",
    "        self.shap_explainers = {}\n",
    "        self.shap_values = {}\n",
    "        self.lime_explainers = {}\n",
    "        \n",
    "        print(f\"ğŸš€ ê°„ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™” (XAI í¬í•¨)\")\n",
    "        print(f\"ğŸ“ ë°ì´í„° ê²½ë¡œ: {data_path}\")\n",
    "        print(f\"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    def load_and_explore_data(self):\n",
    "        \"\"\"ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰ì  ë¶„ì„\"\"\"\n",
    "        print(\"\\nğŸ“Š 1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰\")\n",
    "        \n",
    "        try:\n",
    "            self.df = pd.read_csv(self.data_path)\n",
    "            print(f\"âœ… ë°ì´í„° ë¡œë“œ ì„±ê³µ: {self.df.shape[0]}í–‰ Ã— {self.df.shape[1]}ì—´\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            return False\n",
    "        \n",
    "        # ê¸°ë³¸ ì •ë³´ ì¶œë ¥\n",
    "        print(f\"ğŸ“ˆ ë°ì´í„° ê¸°ë³¸ ì •ë³´:\")\n",
    "        print(f\"   - ì´ í™˜ì ìˆ˜: {len(self.df)}\")\n",
    "        print(f\"   - ì´ ì»¬ëŸ¼ ìˆ˜: {len(self.df.columns)}\")\n",
    "        \n",
    "        # ìƒì¡´ ìƒíƒœ ë¶„í¬\n",
    "        if 'vital_status' in self.df.columns:\n",
    "            status_counts = self.df['vital_status'].value_counts()\n",
    "            print(f\"   - ìƒì¡´ í™˜ì: {status_counts.get('Alive', 0)}ëª…\")\n",
    "            print(f\"   - ì‚¬ë§ í™˜ì: {status_counts.get('Dead', 0)}ëª…\")\n",
    "            print(f\"   - ì‚¬ë§ë¥ : {status_counts.get('Dead', 0)/len(self.df)*100:.1f}%\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        \"\"\"ë°ì´í„° ì „ì²˜ë¦¬\"\"\"\n",
    "        print(\"\\nğŸ”§ 2. ë°ì´í„° ì „ì²˜ë¦¬\")\n",
    "        \n",
    "        # ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ìš© ì„ íƒëœ ì»¬ëŸ¼ë“¤[2]\n",
    "        selected_columns = [\n",
    "            # ìƒì¡´ ê²°ê³¼ ë³€ìˆ˜\n",
    "            'vital_status', 'days_to_death', 'days_to_last_follow_up',\n",
    "            # ê°„ê¸°ëŠ¥ í‰ê°€ (í•µì‹¬ ì˜ˆì¸¡ ì¸ì)[3]\n",
    "            'child_pugh_classification', 'ishak_fibrosis_score',\n",
    "            # ë³‘ê¸° ë° ì¢…ì–‘ íŠ¹ì„±[2]\n",
    "            'ajcc_pathologic_stage', 'ajcc_pathologic_t', 'ajcc_pathologic_n', 'ajcc_pathologic_m',\n",
    "            'tumor_grade', 'morphology',\n",
    "            # í™˜ì ê¸°ë³¸ íŠ¹ì„±[2]\n",
    "            'age_at_diagnosis', 'gender', 'race', 'ethnicity',\n",
    "            # ì¹˜ë£Œ ê´€ë ¨ ë³€ìˆ˜\n",
    "            'treatments_pharmaceutical_treatment_intent_type', \n",
    "            'treatments_pharmaceutical_treatment_type',\n",
    "            'prior_treatment',\n",
    "            # ì¶”ê°€ ì„ìƒ ë³€ìˆ˜\n",
    "            'primary_diagnosis', 'year_of_diagnosis'\n",
    "        ]\n",
    "        \n",
    "        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "        available_columns = [col for col in selected_columns if col in self.df.columns]\n",
    "        missing_columns = [col for col in selected_columns if col not in self.df.columns]\n",
    "        \n",
    "        print(f\"âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {len(available_columns)}ê°œ\")\n",
    "        if missing_columns:\n",
    "            print(f\"âš ï¸  ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_columns}\")\n",
    "        \n",
    "        self.processed_df = self.df[available_columns].copy()\n",
    "        \n",
    "        # ìƒì¡´ ì‹œê°„ ë° ì´ë²¤íŠ¸ ë³€ìˆ˜ ìƒì„±\n",
    "        print(\"ğŸ”„ ìƒì¡´ ë³€ìˆ˜ ìƒì„± ì¤‘...\")\n",
    "        self.processed_df['event'] = (self.processed_df['vital_status'] == 'Dead').astype(int)\n",
    "        \n",
    "        # ìƒì¡´ ì‹œê°„ ê³„ì‚°\n",
    "        self.processed_df['duration'] = self.processed_df['days_to_death'].fillna(\n",
    "            self.processed_df['days_to_last_follow_up']\n",
    "        )\n",
    "        \n",
    "        # ì¹˜ë£Œ íš¨ê³¼ ì§€í‘œ ìƒì„± (ìƒì¡´ ì‹œê°„ ê¸°ë°˜)\n",
    "        self.processed_df['treatment_effectiveness'] = np.where(\n",
    "            self.processed_df['duration'] > self.processed_df['duration'].median(), 1, 0\n",
    "        )\n",
    "        \n",
    "        # ìœ íš¨í•˜ì§€ ì•Šì€ ìƒì¡´ ì‹œê°„ ì œê±°\n",
    "        valid_mask = (self.processed_df['duration'].notna()) & (self.processed_df['duration'] > 0)\n",
    "        self.processed_df = self.processed_df[valid_mask].copy()\n",
    "        \n",
    "        print(f\"âœ… ìœ íš¨í•œ ìƒì¡´ ë°ì´í„°: {len(self.processed_df)}ëª…\")\n",
    "        print(f\"   - ì‚¬ë§ ì´ë²¤íŠ¸: {self.processed_df['event'].sum()}ê±´\")\n",
    "        print(f\"   - ì¤‘ê°„ ìƒì¡´ ì‹œê°„: {self.processed_df['duration'].median():.0f}ì¼\")\n",
    "        print(f\"   - ì¹˜ë£Œ íš¨ê³¼ ì–‘í˜¸: {self.processed_df['treatment_effectiveness'].sum()}ëª…\")\n",
    "        \n",
    "        # ê²°ì¸¡ê°’ ë¶„ì„\n",
    "        print(\"\\nğŸ“‹ ê²°ì¸¡ê°’ ë¶„ì„:\")\n",
    "        missing_analysis = self.processed_df.isnull().sum()\n",
    "        missing_percent = (missing_analysis / len(self.processed_df) * 100).round(1)\n",
    "        \n",
    "        for col in missing_analysis[missing_analysis > 0].index:\n",
    "            print(f\"   - {col}: {missing_analysis[col]}ê°œ ({missing_percent[col]}%)\")\n",
    "        \n",
    "        # ë†’ì€ ê²°ì¸¡ë¥  ì»¬ëŸ¼ ì œê±° (80% ì´ìƒ)\n",
    "        high_missing_cols = missing_percent[missing_percent > 80].index.tolist()\n",
    "        if high_missing_cols:\n",
    "            print(f\"ğŸ—‘ï¸  ë†’ì€ ê²°ì¸¡ë¥  ì»¬ëŸ¼ ì œê±°: {high_missing_cols}\")\n",
    "            self.processed_df = self.processed_df.drop(columns=high_missing_cols)\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def prepare_features(self):\n",
    "        \"\"\"íŠ¹ì„± ì¤€ë¹„ ë° ì¸ì½”ë”© (NAì™€ Unknown ê°’ ì²˜ë¦¬ í¬í•¨)\"\"\"\n",
    "        print(\"\\nğŸ¯ 3. íŠ¹ì„± ì¤€ë¹„ ë° ì¸ì½”ë”©\")\n",
    "        \n",
    "        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "        feature_cols = [col for col in self.processed_df.columns \n",
    "                       if col not in ['vital_status', 'days_to_death', 'days_to_last_follow_up', \n",
    "                                     'event', 'duration', 'treatment_effectiveness']]\n",
    "        \n",
    "        X = self.processed_df[feature_cols].copy()\n",
    "        y_duration = self.processed_df['duration'].values\n",
    "        y_event = self.processed_df['event'].values.astype(bool)\n",
    "        y_effectiveness = self.processed_df['treatment_effectiveness'].values\n",
    "        \n",
    "        print(f\"ğŸ“Š ì´ˆê¸° íŠ¹ì„± ê°œìˆ˜: {len(feature_cols)}\")\n",
    "        print(f\"ğŸ“Š ìƒ˜í”Œ ê°œìˆ˜: {len(X)}\")\n",
    "        \n",
    "        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "        categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "        numerical_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        print(f\"ğŸ”¤ ë²”ì£¼í˜• ë³€ìˆ˜: {len(categorical_cols)}ê°œ\")\n",
    "        print(f\"ğŸ”¢ ìˆ˜ì¹˜í˜• ë³€ìˆ˜: {len(numerical_cols)}ê°œ\")\n",
    "        \n",
    "        # ê²°ì¸¡ê°’ ì²˜ë¦¬\n",
    "        print(\"ğŸ”„ ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...\")\n",
    "        \n",
    "        # ìˆ˜ì¹˜í˜• ë³€ìˆ˜: ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´\n",
    "        if numerical_cols:\n",
    "            num_imputer = SimpleImputer(strategy='median')\n",
    "            X[numerical_cols] = num_imputer.fit_transform(X[numerical_cols])\n",
    "        \n",
    "        # ì„ìƒì ìœ¼ë¡œ ì˜ë¯¸ìˆëŠ” Unknown ê°’ì„ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì»¬ëŸ¼ë“¤[3]\n",
    "        meaningful_unknown_cols = [\n",
    "            'child_pugh_classification', 'ajcc_pathologic_stage', 'ajcc_pathologic_t',\n",
    "            'ajcc_pathologic_n', 'ajcc_pathologic_m', 'tumor_grade',\n",
    "            'treatments_pharmaceutical_treatment_intent_type',\n",
    "            'treatments_pharmaceutical_treatment_type', 'prior_treatment'\n",
    "        ]\n",
    "        \n",
    "        label_encoders = {}\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            if col in X.columns:\n",
    "                print(f\"\\n   ğŸ” {col} ì²˜ë¦¬:\")\n",
    "                \n",
    "                # í˜„ì¬ ê°’ ë¶„í¬ í™•ì¸\n",
    "                value_counts = X[col].value_counts(dropna=False)\n",
    "                print(f\"      - ì „ì²˜ë¦¬ ì „ ë¶„í¬: {dict(list(value_counts.items())[:3])}\")\n",
    "                \n",
    "                # 'NA' ë¬¸ìì—´ì„ ê²°ì¸¡ì¹˜ë¡œ ë³€í™˜\n",
    "                if 'NA' in X[col].values:\n",
    "                    X[col] = X[col].replace('NA', np.nan)\n",
    "                    print(f\"      - 'NA' ë¬¸ìì—´ì„ ê²°ì¸¡ì¹˜ë¡œ ë³€í™˜\")\n",
    "                \n",
    "                # Unknown ê°’ ì²˜ë¦¬ ê²°ì •\n",
    "                has_unknown = X[col].str.contains('Unknown', na=False).any() if X[col].dtype == object else False\n",
    "                \n",
    "                if has_unknown:\n",
    "                    if col in meaningful_unknown_cols:\n",
    "                        print(f\"      - 'Unknown' ê°’ ìœ ì§€ (ì„ìƒì  ì˜ë¯¸ ìˆìŒ)\")\n",
    "                        if X[col].isnull().any():\n",
    "                            mode_value = X[col].mode()\n",
    "                            if not mode_value.empty:\n",
    "                                fill_value = mode_value[0]\n",
    "                                X[col] = X[col].fillna(fill_value)\n",
    "                                print(f\"      - ê²°ì¸¡ì¹˜ë¥¼ '{fill_value}'ë¡œ ëŒ€ì²´\")\n",
    "                    else:\n",
    "                        print(f\"      - 'Unknown' ê°’ì„ ê²°ì¸¡ì¹˜ë¡œ ë³€í™˜ í›„ ëŒ€ì²´\")\n",
    "                        X[col] = X[col].replace('Unknown', np.nan)\n",
    "                        if X[col].isnull().any():\n",
    "                            mode_value = X[col].mode()\n",
    "                            if not mode_value.empty:\n",
    "                                fill_value = mode_value[0]\n",
    "                                X[col] = X[col].fillna(fill_value)\n",
    "                                print(f\"      - ê²°ì¸¡ì¹˜ë¥¼ '{fill_value}'ë¡œ ëŒ€ì²´\")\n",
    "                else:\n",
    "                    if X[col].isnull().any():\n",
    "                        mode_value = X[col].mode()\n",
    "                        if not mode_value.empty:\n",
    "                            fill_value = mode_value[0]\n",
    "                            X[col] = X[col].fillna(fill_value)\n",
    "                            print(f\"      - ê²°ì¸¡ì¹˜ë¥¼ '{fill_value}'ë¡œ ëŒ€ì²´\")\n",
    "        \n",
    "        # ëª¨ë“  ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "        print(\"\\nğŸ”„ ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©:\")\n",
    "        all_categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "        for col in all_categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "            \n",
    "            if col in meaningful_unknown_cols:\n",
    "                mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "                print(f\"   - {col} ì¸ì½”ë”© ë§¤í•‘: {mapping}\")\n",
    "        \n",
    "        # íŠ¹ì„± ìŠ¤ì¼€ì¼ë§\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = pd.DataFrame(\n",
    "            scaler.fit_transform(X),\n",
    "            columns=X.columns,\n",
    "            index=X.index\n",
    "        )\n",
    "        \n",
    "        self.feature_names = X_scaled.columns.tolist()\n",
    "        \n",
    "        # scikit-survival í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "        y_structured = np.array([(event, duration) for event, duration in zip(y_event, y_duration)],\n",
    "                               dtype=[('event', '?'), ('time', '<f8')])\n",
    "        \n",
    "        print(\"âœ… íŠ¹ì„± ì¤€ë¹„ ì™„ë£Œ\")\n",
    "        \n",
    "        return X_scaled, y_structured, y_duration, y_event, y_effectiveness, scaler, label_encoders\n",
    "    \n",
    "    def split_data(self, X, y_structured, y_duration, y_event, y_effectiveness):\n",
    "        \"\"\"ë°ì´í„° ë¶„í• \"\"\"\n",
    "        print(\"\\nâœ‚ï¸  4. ë°ì´í„° ë¶„í•  (í›ˆë ¨:ê²€ì¦:í…ŒìŠ¤íŠ¸ = 60:20:20)\")\n",
    "        \n",
    "        # ë¨¼ì € í›ˆë ¨+ê²€ì¦ vs í…ŒìŠ¤íŠ¸ë¡œ ë¶„í• \n",
    "        X_temp, X_test, y_temp_struct, y_test_struct, y_temp_dur, y_test_dur, y_temp_event, y_test_event, y_temp_eff, y_test_eff = \\\n",
    "            train_test_split(X, y_structured, y_duration, y_event, y_effectiveness,\n",
    "                           test_size=0.2, random_state=42, stratify=y_effectiveness)\n",
    "        \n",
    "        # í›ˆë ¨ vs ê²€ì¦ìœ¼ë¡œ ë¶„í• \n",
    "        X_train, X_val, y_train_struct, y_val_struct, y_train_dur, y_val_dur, y_train_event, y_val_event, y_train_eff, y_val_eff = \\\n",
    "            train_test_split(X_temp, y_temp_struct, y_temp_dur, y_temp_event, y_temp_eff,\n",
    "                           test_size=0.25, random_state=42, stratify=y_temp_eff)\n",
    "        \n",
    "        print(f\"ğŸ“Š í›ˆë ¨ ì„¸íŠ¸: {len(X_train)}ëª… (ì‚¬ë§: {y_train_event.sum()}ëª…, ì¹˜ë£Œíš¨ê³¼ì–‘í˜¸: {y_train_eff.sum()}ëª…)\")\n",
    "        print(f\"ğŸ“Š ê²€ì¦ ì„¸íŠ¸: {len(X_val)}ëª… (ì‚¬ë§: {y_val_event.sum()}ëª…, ì¹˜ë£Œíš¨ê³¼ì–‘í˜¸: {y_val_eff.sum()}ëª…)\")\n",
    "        print(f\"ğŸ“Š í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {len(X_test)}ëª… (ì‚¬ë§: {y_test_event.sum()}ëª…, ì¹˜ë£Œíš¨ê³¼ì–‘í˜¸: {y_test_eff.sum()}ëª…)\")\n",
    "        \n",
    "        return (X_train, X_val, X_test, \n",
    "                y_train_struct, y_val_struct, y_test_struct,\n",
    "                y_train_dur, y_val_dur, y_test_dur,\n",
    "                y_train_event, y_val_event, y_test_event,\n",
    "                y_train_eff, y_val_eff, y_test_eff)\n",
    "    \n",
    "    def train_models(self, X_train, X_val, X_test, \n",
    "                    y_train_struct, y_val_struct, y_test_struct,\n",
    "                    y_train_dur, y_val_dur, y_test_dur,\n",
    "                    y_train_event, y_val_event, y_test_event,\n",
    "                    y_train_eff, y_val_eff, y_test_eff):\n",
    "        \"\"\"ëª¨ë¸ í›ˆë ¨ (ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ íŠ¹í™”)\"\"\"\n",
    "        print(\"\\nğŸ¤– 5. ëª¨ë¸ í›ˆë ¨\")\n",
    "        \n",
    "        # 1. Random Survival Forest (ìƒì¡´ ì˜ˆì¸¡)[7]\n",
    "        print(\"ğŸ”„ Random Survival Forest í›ˆë ¨ ì¤‘...\")\n",
    "        try:\n",
    "            rsf_model = RandomSurvivalForest(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                min_samples_split=10,\n",
    "                min_samples_leaf=5,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            rsf_model.fit(X_train, y_train_struct)\n",
    "            self.models['RSF'] = rsf_model\n",
    "            print(\"âœ… Random Survival Forest í›ˆë ¨ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ RSF ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 2. Cox ë¹„ë¡€ìœ„í—˜ ëª¨ë¸ (ìƒì¡´ ì˜ˆì¸¡)[7]\n",
    "        print(\"ğŸ”„ Cox ë¹„ë¡€ìœ„í—˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...\")\n",
    "        try:\n",
    "            cox_model = CoxPHSurvivalAnalysis(alpha=0.5)\n",
    "            cox_model.fit(X_train, y_train_struct)\n",
    "            self.models['Cox_Survival'] = cox_model\n",
    "            print(\"âœ… Cox ìƒì¡´ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Cox ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 3. Gradient Boosting Survival Analysis\n",
    "        print(\"ğŸ”„ Gradient Boosting Survival Analysis í›ˆë ¨ ì¤‘...\")\n",
    "        try:\n",
    "            gbsa_model = GradientBoostingSurvivalAnalysis(\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=3,\n",
    "                random_state=42\n",
    "            )\n",
    "            gbsa_model.fit(X_train, y_train_struct)\n",
    "            self.models['GBSA'] = gbsa_model\n",
    "            print(\"âœ… Gradient Boosting Survival Analysis í›ˆë ¨ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ GBSA ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 4. Random Forest (ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜)\n",
    "        print(\"ğŸ”„ Random Forest ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...\")\n",
    "        try:\n",
    "            rf_classifier = RandomForestClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            rf_classifier.fit(X_train, y_train_eff)\n",
    "            self.models['RF_Treatment'] = rf_classifier\n",
    "            print(\"âœ… Random Forest ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ RF ì¹˜ë£Œ íš¨ê³¼ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 5. XGBoost (ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜)[9]\n",
    "        print(\"ğŸ”„ XGBoost ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...\")\n",
    "        try:\n",
    "            xgb_model = xgb.XGBClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=6,\n",
    "                learning_rate=0.1,\n",
    "                random_state=42,\n",
    "                eval_metric='logloss'\n",
    "            )\n",
    "            xgb_model.fit(X_train, y_train_eff)\n",
    "            self.models['XGB_Treatment'] = xgb_model\n",
    "            print(\"âœ… XGBoost ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ XGBoost ì¹˜ë£Œ íš¨ê³¼ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 6. LightGBM (ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜)[9]\n",
    "        print(\"ğŸ”„ LightGBM ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì¤‘...\")\n",
    "        try:\n",
    "            lgb_model = lgb.LGBMClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=6,\n",
    "                learning_rate=0.1,\n",
    "                random_state=42,\n",
    "                verbose=-1\n",
    "            )\n",
    "            lgb_model.fit(X_train, y_train_eff)\n",
    "            self.models['LGB_Treatment'] = lgb_model\n",
    "            print(\"âœ… LightGBM ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ LightGBM ì¹˜ë£Œ íš¨ê³¼ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 7. Random Forest (ìƒì¡´ ì‹œê°„ íšŒê·€)\n",
    "        print(\"ğŸ”„ Random Forest ìƒì¡´ ì‹œê°„ íšŒê·€ ëª¨ë¸ í›ˆë ¨ ì¤‘...\")\n",
    "        try:\n",
    "            rf_regressor = RandomForestRegressor(\n",
    "                n_estimators=100,\n",
    "                max_depth=10,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            rf_regressor.fit(X_train, y_train_dur)\n",
    "            self.models['RF_Duration'] = rf_regressor\n",
    "            print(\"âœ… Random Forest ìƒì¡´ ì‹œê°„ íšŒê·€ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ RF ìƒì¡´ ì‹œê°„ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        print(f\"\\nğŸ¯ ì´ {len(self.models)}ê°œ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def evaluate_models(self, X_train, X_val, X_test,\n",
    "                       y_train_struct, y_val_struct, y_test_struct,\n",
    "                       y_train_dur, y_val_dur, y_test_dur,\n",
    "                       y_train_event, y_val_event, y_test_event,\n",
    "                       y_train_eff, y_val_eff, y_test_eff):\n",
    "        \"\"\"ëª¨ë¸ í‰ê°€\"\"\"\n",
    "        print(\"\\nğŸ“ˆ 6. ëª¨ë¸ í‰ê°€\")\n",
    "        \n",
    "        datasets = {\n",
    "            'Train': (X_train, y_train_struct, y_train_dur, y_train_event, y_train_eff),\n",
    "            'Validation': (X_val, y_val_struct, y_val_dur, y_val_event, y_val_eff),\n",
    "            'Test': (X_test, y_test_struct, y_test_dur, y_test_event, y_test_eff)\n",
    "        }\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "            print(f\"\\nğŸ” {model_name} ëª¨ë¸ í‰ê°€:\")\n",
    "            self.results[model_name] = {}\n",
    "            \n",
    "            for dataset_name, (X, y_struct, y_dur, y_event, y_eff) in datasets.items():\n",
    "                try:\n",
    "                    if model_name in ['RSF', 'Cox_Survival', 'GBSA']:\n",
    "                        # ìƒì¡´ ëª¨ë¸ í‰ê°€\n",
    "                        risk_scores = model.predict(X)\n",
    "                        c_index = concordance_index_censored(y_struct['event'], y_struct['time'], risk_scores)[0]\n",
    "                        self.results[model_name][dataset_name] = {'c_index': c_index}\n",
    "                        print(f\"   {dataset_name}: C-index = {c_index:.3f}\")\n",
    "                    \n",
    "                    elif model_name == 'RF_Duration':\n",
    "                        # íšŒê·€ ëª¨ë¸ í‰ê°€\n",
    "                        y_pred = model.predict(X)\n",
    "                        mse = mean_squared_error(y_dur, y_pred)\n",
    "                        r2 = r2_score(y_dur, y_pred)\n",
    "                        self.results[model_name][dataset_name] = {'mse': mse, 'r2': r2}\n",
    "                        print(f\"   {dataset_name}: MSE = {mse:.0f}, RÂ² = {r2:.3f}\")\n",
    "                    \n",
    "                    else:\n",
    "                        # ë¶„ë¥˜ ëª¨ë¸ í‰ê°€ (ì¹˜ë£Œ íš¨ê³¼)\n",
    "                        y_pred = model.predict(X)\n",
    "                        accuracy = (y_pred == y_eff).mean()\n",
    "                        \n",
    "                        try:\n",
    "                            y_proba = model.predict_proba(X)\n",
    "                            auc_score = roc_auc_score(y_eff, y_proba[:, 1])\n",
    "                        except:\n",
    "                            auc_score = np.nan\n",
    "                        \n",
    "                        self.results[model_name][dataset_name] = {\n",
    "                            'accuracy': accuracy,\n",
    "                            'auc': auc_score\n",
    "                        }\n",
    "                        print(f\"   {dataset_name}: Accuracy = {accuracy:.3f}, AUC = {auc_score:.3f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   âŒ {dataset_name} í‰ê°€ ì‹¤íŒ¨: {e}\")\n",
    "                    self.results[model_name][dataset_name] = {'error': str(e)}\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def explain_models(self, X_train, X_test):\n",
    "        \"\"\"XAI ëª¨ë¸ ì„¤ëª… ìƒì„±[9]\"\"\"\n",
    "        print(\"\\nğŸ” XAI ëª¨ë¸ ì„¤ëª… ìƒì„±\")\n",
    "        \n",
    "        # SHAP ì„¤ëª…ê¸° ì´ˆê¸°í™”\n",
    "        print(\"ğŸ”„ SHAP ì„¤ëª… ìƒì„± ì¤‘...\")\n",
    "        tree_models = ['RF_Treatment', 'XGB_Treatment', 'LGB_Treatment', 'RF_Duration']\n",
    "        \n",
    "        for model_name in tree_models:\n",
    "            if model_name in self.models:\n",
    "                try:\n",
    "                    X_test_sample = X_test.iloc[:50]  # ì²˜ìŒ 50ê°œ ìƒ˜í”Œë§Œ ì‚¬ìš©\n",
    "                    \n",
    "                    explainer = shap.TreeExplainer(self.models[model_name])\n",
    "                    shap_values = explainer.shap_values(X_test_sample)\n",
    "                    \n",
    "                    self.shap_explainers[model_name] = explainer\n",
    "                    self.shap_values[model_name] = shap_values\n",
    "                    print(f\"âœ… {model_name} SHAP ì„¤ëª… ìƒì„± ì™„ë£Œ\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ {model_name} SHAP ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # LIME ì„¤ëª…ê¸° ì´ˆê¸°í™”\n",
    "        print(\"\\nğŸ”„ LIME ì„¤ëª… ìƒì„± ì¤‘...\")\n",
    "        classification_models = ['RF_Treatment', 'XGB_Treatment', 'LGB_Treatment']\n",
    "        \n",
    "        for model_name in classification_models:\n",
    "            if model_name in self.models:\n",
    "                try:\n",
    "                    explainer = lime_tabular.LimeTabularExplainer(\n",
    "                        training_data=X_train.values,\n",
    "                        feature_names=self.feature_names,\n",
    "                        class_names=['ì¹˜ë£Œíš¨ê³¼ ë¶ˆëŸ‰', 'ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸'],\n",
    "                        mode='classification',\n",
    "                        discretize_continuous=True\n",
    "                    )\n",
    "                    self.lime_explainers[model_name] = explainer\n",
    "                    print(f\"âœ… {model_name} LIME ì„¤ëª…ê¸° ìƒì„± ì™„ë£Œ\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ {model_name} LIME ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def generate_xai_visualizations(self, X_test, sample_index=0):\n",
    "        \"\"\"XAI ì‹œê°í™” ìƒì„± ë° ì €ì¥ (ìˆ˜ì •ëœ ë²„ì „)\"\"\"\n",
    "        print(\"\\nğŸ“Š XAI ì‹œê°í™” ìƒì„±\")\n",
    "        \n",
    "        # SHAP ì‹œê°í™”\n",
    "        shap_figures = []\n",
    "        for model_name in self.shap_explainers:\n",
    "            try:\n",
    "                print(f\"ğŸ”„ {model_name} SHAP ì‹œê°í™” ë””ë²„ê¹…:\")\n",
    "                \n",
    "                shap_vals = self.shap_values[model_name]\n",
    "                print(f\"   - SHAP ê°’ íƒ€ì…: {type(shap_vals)}\")\n",
    "                print(f\"   - SHAP ê°’ í˜•íƒœ: {np.array(shap_vals).shape if isinstance(shap_vals, list) else shap_vals.shape}\")\n",
    "                \n",
    "                # ì´ì§„ ë¶„ë¥˜ SHAP ê°’ ì²˜ë¦¬ (í•µì‹¬ ìˆ˜ì • ë¶€ë¶„)\n",
    "                if isinstance(shap_vals, list) and len(shap_vals) == 2:\n",
    "                    # ì´ì§„ ë¶„ë¥˜: ì–‘ì„± í´ë˜ìŠ¤(ì¸ë±ìŠ¤ 1)ë§Œ ì‚¬ìš©\n",
    "                    shap_vals_to_plot = shap_vals[1]\n",
    "                    expected_val = self.shap_explainers[model_name].expected_value[1]\n",
    "                    print(f\"   - ì´ì§„ ë¶„ë¥˜ ê°ì§€: ì–‘ì„± í´ë˜ìŠ¤ SHAP ê°’ ì‚¬ìš©\")\n",
    "                    print(f\"   - ì–‘ì„± í´ë˜ìŠ¤ SHAP í˜•íƒœ: {shap_vals_to_plot.shape}\")\n",
    "                    \n",
    "                elif hasattr(shap_vals, 'shape') and shap_vals.ndim == 3:\n",
    "                    # 3ì°¨ì› ë°°ì—´: (ìƒ˜í”Œ, íŠ¹ì„±, í´ë˜ìŠ¤)\n",
    "                    shap_vals_to_plot = shap_vals[:, :, 1]  # ì–‘ì„± í´ë˜ìŠ¤\n",
    "                    expected_val = (self.shap_explainers[model_name].expected_value[1] \n",
    "                                if hasattr(self.shap_explainers[model_name].expected_value, '__len__') \n",
    "                                else self.shap_explainers[model_name].expected_value)\n",
    "                    print(f\"   - 3ì°¨ì› ë°°ì—´ ê°ì§€: ì–‘ì„± í´ë˜ìŠ¤ ì„ íƒ\")\n",
    "                    \n",
    "                else:\n",
    "                    # 2ì°¨ì› ë°°ì—´ ë˜ëŠ” ê¸°íƒ€\n",
    "                    shap_vals_to_plot = shap_vals\n",
    "                    expected_val = (self.shap_explainers[model_name].expected_value \n",
    "                                if not hasattr(self.shap_explainers[model_name].expected_value, '__len__')\n",
    "                                else self.shap_explainers[model_name].expected_value[0])\n",
    "                    print(f\"   - 2ì°¨ì› ë°°ì—´ ì‚¬ìš©\")\n",
    "                \n",
    "                print(f\"   - ìµœì¢… SHAP í˜•íƒœ: {shap_vals_to_plot.shape}\")\n",
    "                print(f\"   - ê¸°ëŒ“ê°’: {expected_val}\")\n",
    "                \n",
    "                # Summary plot\n",
    "                plt.figure(figsize=(10,6))\n",
    "                shap.summary_plot(shap_vals_to_plot, X_test.iloc[:50], \n",
    "                                feature_names=self.feature_names,\n",
    "                                plot_type=\"bar\", show=False)\n",
    "                plt.title(f\"{model_name} íŠ¹ì„± ì¤‘ìš”ë„ (SHAP)\")\n",
    "                shap_summary_path = f\"shap_summary_{model_name}.png\"\n",
    "                plt.savefig(shap_summary_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "                # Individual waterfall plot\n",
    "                plt.figure(figsize=(12,6))\n",
    "                \n",
    "                # ê°œë³„ ìƒ˜í”Œ SHAP ê°’ ì¶”ì¶œ (ìŠ¤ì¹¼ë¼ ë³€í™˜ ì˜¤ë¥˜ ë°©ì§€)\n",
    "                if shap_vals_to_plot.ndim == 2:\n",
    "                    individual_shap = shap_vals_to_plot[sample_index, :]  # ëª…ì‹œì  ì¸ë±ì‹±\n",
    "                else:\n",
    "                    individual_shap = shap_vals_to_plot\n",
    "                \n",
    "                print(f\"   - ê°œë³„ SHAP í˜•íƒœ: {individual_shap.shape}\")\n",
    "                \n",
    "                # ì•ˆì „í•œ ê¸°ëŒ“ê°’ ì²˜ë¦¬\n",
    "                if hasattr(expected_val, '__len__') and len(expected_val) > 0:\n",
    "                    base_value = float(expected_val[0]) if hasattr(expected_val[0], '__float__') else 0.0\n",
    "                else:\n",
    "                    base_value = float(expected_val) if hasattr(expected_val, '__float__') else 0.0\n",
    "                \n",
    "                print(f\"   - ê¸°ëŒ“ê°’ (ìŠ¤ì¹¼ë¼): {base_value}\")\n",
    "                \n",
    "                # Waterfall plot ìƒì„±\n",
    "                shap.waterfall_plot(\n",
    "                    shap.Explanation(\n",
    "                        values=individual_shap.astype(float),  # ëª…ì‹œì  float ë³€í™˜\n",
    "                        base_values=base_value,\n",
    "                        data=X_test.iloc[sample_index].values.astype(float),  # ëª…ì‹œì  float ë³€í™˜\n",
    "                        feature_names=self.feature_names\n",
    "                    ),\n",
    "                    show=False\n",
    "                )\n",
    "                plt.title(f\"{model_name} ê°œë³„ ì„¤ëª… (ìƒ˜í”Œ {sample_index})\")\n",
    "                shap_waterfall_path = f\"shap_waterfall_{model_name}_{sample_index}.png\"\n",
    "                plt.savefig(shap_waterfall_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                \n",
    "                shap_figures.extend([shap_summary_path, shap_waterfall_path])\n",
    "                print(f\"âœ… {model_name} SHAP ì‹œê°í™” ì™„ë£Œ\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {model_name} SHAP ì‹œê°í™” ì‹¤íŒ¨: {e}\")\n",
    "                print(f\"   ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        # LIME ì‹œê°í™”ëŠ” ê¸°ì¡´ê³¼ ë™ì¼\n",
    "        lime_figures = []\n",
    "        for model_name in self.lime_explainers:\n",
    "            try:\n",
    "                exp = self.lime_explainers[model_name].explain_instance(\n",
    "                    X_test.iloc[sample_index].values,\n",
    "                    self.models[model_name].predict_proba,\n",
    "                    num_features=5\n",
    "                )\n",
    "                lime_path = f\"lime_explanation_{model_name}_{sample_index}.png\"\n",
    "                fig = exp.as_pyplot_figure()\n",
    "                plt.title(f\"{model_name} LIME ì„¤ëª… (ìƒ˜í”Œ {sample_index})\")\n",
    "                plt.savefig(lime_path, bbox_inches='tight')\n",
    "                plt.close()\n",
    "                lime_figures.append(lime_path)\n",
    "                print(f\"âœ… {model_name} LIME ì‹œê°í™” ì™„ë£Œ\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {model_name} LIME ì‹œê°í™” ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        return shap_figures, lime_figures\n",
    "\n",
    "    def plot_results(self, X_test, y_test_dur, y_test_event, y_test_eff):\n",
    "        \"\"\"ê²°ê³¼ ì‹œê°í™” (ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ íŠ¹í™”)\"\"\"\n",
    "        print(\"\\nğŸ“Š 7. ê²°ê³¼ ì‹œê°í™”\")\n",
    "        \n",
    "        fig = plt.figure(figsize=(25, 35))\n",
    "        gs = fig.add_gridspec(5, 3)\n",
    "        axes = [\n",
    "            fig.add_subplot(gs[0, 0]),  # ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ ê³¡ì„ \n",
    "            fig.add_subplot(gs[0, 1]),  # ì¹˜ë£Œíš¨ê³¼ ë¶„í¬\n",
    "            fig.add_subplot(gs[0, 2]),  # ìƒì¡´ ëª¨ë¸ ì„±ëŠ¥\n",
    "            fig.add_subplot(gs[1, 0]),  # ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜ ì„±ëŠ¥\n",
    "            fig.add_subplot(gs[1, 1]),  # íšŒê·€ ëª¨ë¸ ì„±ëŠ¥\n",
    "            fig.add_subplot(gs[1, 2]),  # íŠ¹ì„± ì¤‘ìš”ë„ (XGBoost)\n",
    "            fig.add_subplot(gs[2, 0]),  # íŠ¹ì„± ì¤‘ìš”ë„ (LightGBM)\n",
    "            fig.add_subplot(gs[2, 1]),  # ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ìœ¨\n",
    "            fig.add_subplot(gs[2, 2]),  # ëª¨ë¸ ì„±ëŠ¥ ì¢…í•©\n",
    "            fig.add_subplot(gs[3, :]),  # SHAP ì‹œê°í™”\n",
    "            fig.add_subplot(gs[4, :])   # LIME ì‹œê°í™”\n",
    "        ]\n",
    "        \n",
    "        # 1. ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ ê³¡ì„ \n",
    "        print(\"ğŸ” ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ ê³¡ì„  ìƒì„± ì¤‘...\")\n",
    "        for eff_level in [0, 1]:\n",
    "            mask = (y_test_eff == eff_level)\n",
    "            if mask.sum() > 5:\n",
    "                kmf = KaplanMeierFitter()\n",
    "                label = 'ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸' if eff_level == 1 else 'ì¹˜ë£Œíš¨ê³¼ ë¶ˆëŸ‰'\n",
    "                kmf.fit(y_test_dur[mask], y_test_event[mask], label=f'{label} (n={mask.sum()})')\n",
    "                kmf.plot_survival_function(ax=axes[0])\n",
    "        \n",
    "        axes[0].set_title('ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ ê³¡ì„  (Kaplan-Meier)')\n",
    "        axes[0].set_ylabel('ìƒì¡´ í™•ë¥ ')\n",
    "        axes[0].set_xlabel('ì‹œê°„ (ì¼)')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. ì¹˜ë£Œíš¨ê³¼ ë¶„í¬\n",
    "        eff_counts = pd.Series(y_test_eff).value_counts().sort_index()\n",
    "        colors = ['lightcoral', 'lightgreen']\n",
    "        labels = ['ì¹˜ë£Œíš¨ê³¼ ë¶ˆëŸ‰', 'ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸']\n",
    "        bars = axes[1].bar([labels[i] for i in eff_counts.index], \n",
    "                          eff_counts.values, color=colors)\n",
    "        axes[1].set_title('í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì¹˜ë£Œíš¨ê³¼ ë¶„í¬')\n",
    "        axes[1].set_ylabel('í™˜ì ìˆ˜')\n",
    "        \n",
    "        for bar, value in zip(bars, eff_counts.values):\n",
    "            axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                        f'{value}ëª…', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 3. ìƒì¡´ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\n",
    "        survival_models = ['RSF', 'Cox_Survival', 'GBSA']\n",
    "        survival_c_indices = []\n",
    "        survival_names = []\n",
    "        \n",
    "        for model_name in survival_models:\n",
    "            if model_name in self.results and 'Test' in self.results[model_name]:\n",
    "                c_index = self.results[model_name]['Test'].get('c_index', np.nan)\n",
    "                if not np.isnan(c_index):\n",
    "                    survival_c_indices.append(c_index)\n",
    "                    survival_names.append(model_name)\n",
    "        \n",
    "        if survival_c_indices:\n",
    "            bars = axes[2].bar(survival_names, survival_c_indices, \n",
    "                             color=['skyblue', 'lightcoral', 'lightgreen'][:len(survival_names)])\n",
    "            axes[2].set_title('ìƒì¡´ ëª¨ë¸ ì„±ëŠ¥ (C-index)')\n",
    "            axes[2].set_ylabel('C-index')\n",
    "            axes[2].set_ylim(0.5, 1.0)\n",
    "            axes[2].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            for bar, value in zip(bars, survival_c_indices):\n",
    "                axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                            f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 4. ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥\n",
    "        classification_models = ['RF_Treatment', 'XGB_Treatment', 'LGB_Treatment']\n",
    "        classification_accuracies = []\n",
    "        classification_names = []\n",
    "        \n",
    "        for model_name in classification_models:\n",
    "            if model_name in self.results and 'Test' in self.results[model_name]:\n",
    "                accuracy = self.results[model_name]['Test'].get('accuracy', np.nan)\n",
    "                if not np.isnan(accuracy):\n",
    "                    classification_accuracies.append(accuracy)\n",
    "                    classification_names.append(model_name)\n",
    "        \n",
    "        if classification_accuracies:\n",
    "            bars = axes[3].bar(classification_names, classification_accuracies, \n",
    "                             color=['lightgreen', 'orange', 'purple'][:len(classification_names)])\n",
    "            axes[3].set_title('ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥ (Accuracy)')\n",
    "            axes[3].set_ylabel('Accuracy')\n",
    "            axes[3].set_ylim(0, 1.0)\n",
    "            axes[3].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            for bar, value in zip(bars, classification_accuracies):\n",
    "                axes[3].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                            f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 5. íšŒê·€ ëª¨ë¸ ì„±ëŠ¥\n",
    "        if 'RF_Duration' in self.results and 'Test' in self.results['RF_Duration']:\n",
    "            r2 = self.results['RF_Duration']['Test'].get('r2', np.nan)\n",
    "            mse = self.results['RF_Duration']['Test'].get('mse', np.nan)\n",
    "            \n",
    "            if not np.isnan(r2):\n",
    "                bars = axes[4].bar(['RF_Duration'], [r2], color='gold')\n",
    "                axes[4].set_title('ìƒì¡´ì‹œê°„ ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ (RÂ²)')\n",
    "                axes[4].set_ylabel('RÂ²')\n",
    "                axes[4].set_ylim(0, 1.0)\n",
    "                axes[4].grid(True, alpha=0.3, axis='y')\n",
    "                \n",
    "                axes[4].text(bars[0].get_x() + bars[0].get_width()/2, bars[0].get_height() + 0.01,\n",
    "                            f'{r2:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 6-7. íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™”\n",
    "        for idx, model_name in enumerate(['XGB_Treatment', 'LGB_Treatment']):\n",
    "            ax_idx = 5 + idx\n",
    "            if model_name in self.models:\n",
    "                try:\n",
    "                    importance = self.models[model_name].feature_importances_\n",
    "                    feature_importance_df = pd.DataFrame({\n",
    "                        'feature': self.feature_names,\n",
    "                        'importance': importance\n",
    "                    }).sort_values('importance', ascending=True).tail(10)\n",
    "                    \n",
    "                    color = 'orange' if 'XGB' in model_name else 'purple'\n",
    "                    bars = axes[ax_idx].barh(range(len(feature_importance_df)), \n",
    "                                           feature_importance_df['importance'],\n",
    "                                           color=color)\n",
    "                    \n",
    "                    axes[ax_idx].set_yticks(range(len(feature_importance_df)))\n",
    "                    axes[ax_idx].set_yticklabels(feature_importance_df['feature'], fontsize=10)\n",
    "                    axes[ax_idx].set_title(f'íŠ¹ì„± ì¤‘ìš”ë„ ({model_name})', fontsize=12, fontweight='bold')\n",
    "                    axes[ax_idx].set_xlabel('ì¤‘ìš”ë„')\n",
    "                    axes[ax_idx].grid(True, alpha=0.3, axis='x')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ {model_name} íŠ¹ì„± ì¤‘ìš”ë„ ì‹œê°í™” ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        # 8. ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ìœ¨ ìš”ì•½\n",
    "        survival_summary = []\n",
    "        time_points = [365, 1095, 1825]  # 1ë…„, 3ë…„, 5ë…„\n",
    "        \n",
    "        for eff_level in [0, 1]:\n",
    "            mask = (y_test_eff == eff_level)\n",
    "            if mask.sum() > 5:\n",
    "                kmf = KaplanMeierFitter()\n",
    "                kmf.fit(y_test_dur[mask], y_test_event[mask])\n",
    "                \n",
    "                survival_rates = []\n",
    "                for time_point in time_points:\n",
    "                    try:\n",
    "                        survival_rate = kmf.survival_function_at_times(time_point).values[0]\n",
    "                        survival_rates.append(survival_rate * 100)\n",
    "                    except:\n",
    "                        survival_rates.append(np.nan)\n",
    "                \n",
    "                survival_summary.append(survival_rates)\n",
    "            else:\n",
    "                survival_summary.append([np.nan, np.nan, np.nan])\n",
    "        \n",
    "        # ìƒì¡´ìœ¨ íˆíŠ¸ë§µ\n",
    "        survival_df = pd.DataFrame(survival_summary, \n",
    "                                  index=['ì¹˜ë£Œíš¨ê³¼ ë¶ˆëŸ‰', 'ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸'],\n",
    "                                  columns=['1ë…„', '3ë…„', '5ë…„'])\n",
    "        \n",
    "        sns.heatmap(survival_df, annot=True, fmt='.1f', cmap='RdYlGn', \n",
    "                   ax=axes[7], cbar_kws={'label': 'ìƒì¡´ìœ¨ (%)'})\n",
    "        axes[7].set_title('ì¹˜ë£Œíš¨ê³¼ë³„ ìƒì¡´ìœ¨ ìš”ì•½')\n",
    "        axes[7].set_ylabel('ì¹˜ë£Œíš¨ê³¼ ê·¸ë£¹')\n",
    "        \n",
    "        # 9. ëª¨ë¸ ì„±ëŠ¥ ì¢…í•©\n",
    "        all_models_performance = {}\n",
    "        \n",
    "        # ìƒì¡´ ëª¨ë¸ C-index\n",
    "        for model_name in ['RSF', 'Cox_Survival', 'GBSA']:\n",
    "            if model_name in self.results and 'Test' in self.results[model_name]:\n",
    "                c_index = self.results[model_name]['Test'].get('c_index', np.nan)\n",
    "                if not np.isnan(c_index):\n",
    "                    all_models_performance[f'{model_name}_C-index'] = c_index\n",
    "        \n",
    "        # ë¶„ë¥˜ ëª¨ë¸ Accuracy\n",
    "        for model_name in ['RF_Treatment', 'XGB_Treatment', 'LGB_Treatment']:\n",
    "            if model_name in self.results and 'Test' in self.results[model_name]:\n",
    "                accuracy = self.results[model_name]['Test'].get('accuracy', np.nan)\n",
    "                if not np.isnan(accuracy):\n",
    "                    all_models_performance[f'{model_name}_Accuracy'] = accuracy\n",
    "        \n",
    "        if all_models_performance:\n",
    "            model_names = list(all_models_performance.keys())\n",
    "            model_scores = list(all_models_performance.values())\n",
    "            \n",
    "            bars = axes[8].bar(range(len(model_names)), model_scores, \n",
    "                             color=['skyblue', 'lightcoral', 'lightgreen', \n",
    "                                   'gold', 'orange', 'purple'][:len(model_names)])\n",
    "            axes[8].set_title('ì „ì²´ ëª¨ë¸ ì„±ëŠ¥ ì¢…í•©')\n",
    "            axes[8].set_ylabel('ì„±ëŠ¥ ì ìˆ˜')\n",
    "            axes[8].set_xticks(range(len(model_names)))\n",
    "            axes[8].set_xticklabels(model_names, rotation=45, ha='right')\n",
    "            axes[8].grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            for bar, value in zip(bars, model_scores):\n",
    "                axes[8].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                            f'{value:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=8)\n",
    "        \n",
    "        # 10-11. XAI ì‹œê°í™” ë¡œë“œ\n",
    "        try:\n",
    "            # SHAP ì‹œê°í™”\n",
    "            model_name = 'XGB_Treatment' if 'XGB_Treatment' in self.shap_explainers else 'RF_Treatment'\n",
    "            if model_name:\n",
    "                img = plt.imread(f\"shap_summary_{model_name}.png\")\n",
    "                axes[9].imshow(img)\n",
    "                axes[9].axis('off')\n",
    "                axes[9].set_title('SHAP ì „ì—­ ì„¤ëª… (ì¹˜ë£Œíš¨ê³¼ ì˜ˆì¸¡)', fontsize=12)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ SHAP ì‹œê°í™” ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            axes[9].text(0.5, 0.5, 'SHAP ì‹œê°í™” ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨', \n",
    "                        ha='center', va='center', transform=axes[9].transAxes,\n",
    "                        fontsize=12, fontweight='bold')\n",
    "        \n",
    "        try:\n",
    "            # LIME ì‹œê°í™”\n",
    "            model_name = 'XGB_Treatment' if 'XGB_Treatment' in self.lime_explainers else 'RF_Treatment'\n",
    "            if model_name:\n",
    "                img = plt.imread(f\"lime_explanation_{model_name}_0.png\")\n",
    "                axes[10].imshow(img)\n",
    "                axes[10].axis('off')\n",
    "                axes[10].set_title('LIME ê°œë³„ ì„¤ëª… (ì²« ë²ˆì§¸ í™˜ì)', fontsize=12)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ LIME ì‹œê°í™” ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            axes[10].text(0.5, 0.5, 'LIME ì‹œê°í™” ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨', \n",
    "                         ha='center', va='center', transform=axes[10].transAxes,\n",
    "                         fontsize=12, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        save_path = \"liver_cancer_treatment_effect_prediction_with_xai.png\"\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"ğŸ“ ì‹œê°í™” ê²°ê³¼ ì €ì¥: {save_path}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±\"\"\"\n",
    "        print(\"\\nğŸ“‹ 8. ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±\")\n",
    "        \n",
    "        report = []\n",
    "        report.append(\"=\"*60)\n",
    "        report.append(\"ê°„ì•” í™˜ì ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ë¶„ì„ ê²°ê³¼\")\n",
    "        report.append(\"=\"*60)\n",
    "        report.append(f\"ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        report.append(f\"ë°ì´í„° ê²½ë¡œ: {self.data_path}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # ë°ì´í„° ìš”ì•½\n",
    "        report.append(\"ğŸ“Š ë°ì´í„° ìš”ì•½\")\n",
    "        report.append(\"-\" * 30)\n",
    "        report.append(f\"ì´ í™˜ì ìˆ˜: {len(self.processed_df)}\")\n",
    "        report.append(f\"ì‚¬ë§ í™˜ì ìˆ˜: {self.processed_df['event'].sum()}\")\n",
    "        report.append(f\"ì‚¬ë§ë¥ : {self.processed_df['event'].mean()*100:.1f}%\")\n",
    "        report.append(f\"ì¤‘ê°„ ìƒì¡´ ì‹œê°„: {self.processed_df['duration'].median():.0f}ì¼\")\n",
    "        report.append(f\"ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸ í™˜ì: {self.processed_df['treatment_effectiveness'].sum()}ëª…\")\n",
    "        report.append(f\"ì¹˜ë£Œíš¨ê³¼ ì–‘í˜¸ìœ¨: {self.processed_df['treatment_effectiveness'].mean()*100:.1f}%\")\n",
    "        report.append(f\"ì‚¬ìš©ëœ íŠ¹ì„± ìˆ˜: {len(self.feature_names)}\")\n",
    "        report.append(\"\")\n",
    "        \n",
    "        # ëª¨ë¸ ì„±ëŠ¥\n",
    "        report.append(\"ğŸ¤– ëª¨ë¸ ì„±ëŠ¥\")\n",
    "        report.append(\"-\" * 30)\n",
    "        \n",
    "        # ìƒì¡´ ëª¨ë¸ ì„±ëŠ¥\n",
    "        report.append(\"\\nìƒì¡´ ì˜ˆì¸¡ ëª¨ë¸ (C-index):\")\n",
    "        survival_models = ['RSF', 'Cox_Survival', 'GBSA']\n",
    "        for model_name in survival_models:\n",
    "            if model_name in self.results:\n",
    "                for dataset in ['Train', 'Validation', 'Test']:\n",
    "                    if dataset in self.results[model_name]:\n",
    "                        metrics = self.results[model_name][dataset]\n",
    "                        if 'c_index' in metrics:\n",
    "                            report.append(f\"  {model_name} {dataset}: C-index = {metrics['c_index']:.3f}\")\n",
    "        \n",
    "        # ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥\n",
    "        report.append(\"\\nì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜ ëª¨ë¸ (Accuracy):\")\n",
    "        classification_models = ['RF_Treatment', 'XGB_Treatment', 'LGB_Treatment']\n",
    "        for model_name in classification_models:\n",
    "            if model_name in self.results:\n",
    "                for dataset in ['Train', 'Validation', 'Test']:\n",
    "                    if dataset in self.results[model_name]:\n",
    "                        metrics = self.results[model_name][dataset]\n",
    "                        if 'accuracy' in metrics:\n",
    "                            report.append(f\"  {model_name} {dataset}: Accuracy = {metrics['accuracy']:.3f}\")\n",
    "        \n",
    "        # íšŒê·€ ëª¨ë¸ ì„±ëŠ¥\n",
    "        report.append(\"\\nìƒì¡´ì‹œê°„ ì˜ˆì¸¡ ëª¨ë¸ (RÂ²):\")\n",
    "        if 'RF_Duration' in self.results:\n",
    "            for dataset in ['Train', 'Validation', 'Test']:\n",
    "                if dataset in self.results['RF_Duration']:\n",
    "                    metrics = self.results['RF_Duration'][dataset]\n",
    "                    if 'r2' in metrics:\n",
    "                        report.append(f\"  RF_Duration {dataset}: RÂ² = {metrics['r2']:.3f}\")\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸\n",
    "        test_performances = {}\n",
    "        for model_name in self.results:\n",
    "            if 'Test' in self.results[model_name]:\n",
    "                metrics = self.results[model_name]['Test']\n",
    "                if 'c_index' in metrics:\n",
    "                    test_performances[f\"{model_name}_C-index\"] = metrics['c_index']\n",
    "                elif 'accuracy' in metrics:\n",
    "                    test_performances[f\"{model_name}_Accuracy\"] = metrics['accuracy']\n",
    "                elif 'r2' in metrics:\n",
    "                    test_performances[f\"{model_name}_RÂ²\"] = metrics['r2']\n",
    "        \n",
    "        if test_performances:\n",
    "            best_model = max(test_performances, key=test_performances.get)\n",
    "            report.append(f\"\\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model} (ì ìˆ˜: {test_performances[best_model]:.3f})\")\n",
    "        \n",
    "        report.append(\"\")\n",
    "        report.append(\"â„¹ï¸  ì‚¬ìš©ëœ ëª¨ë¸:\")\n",
    "        report.append(\"   ìƒì¡´ ì˜ˆì¸¡: Random Survival Forest, Cox, GBSA\")\n",
    "        report.append(\"   ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜: Random Forest, XGBoost, LightGBM\")\n",
    "        report.append(\"   ìƒì¡´ì‹œê°„ ì˜ˆì¸¡: Random Forest Regressor\")\n",
    "        report.append(\"   XAI: SHAP, LIME ì ìš©\")\n",
    "        report.append(\"\")\n",
    "        report.append(\"=\"*60)\n",
    "        \n",
    "        # ë³´ê³ ì„œ ì €ì¥\n",
    "        report_text = \"\\n\".join(report)\n",
    "        with open(\"liver_cancer_treatment_effect_prediction_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(report_text)\n",
    "        \n",
    "        print(\"ğŸ“ ë³´ê³ ì„œ ì €ì¥: liver_cancer_treatment_effect_prediction_report.txt\")\n",
    "        print(\"\\n\" + report_text)\n",
    "        \n",
    "        return report_text\n",
    "    \n",
    "    def save_models(self):\n",
    "        \"\"\"ëª¨ë¸ ì €ì¥\"\"\"\n",
    "        print(\"\\nğŸ’¾ 9. ëª¨ë¸ ì €ì¥\")\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "            try:\n",
    "                filename = f\"liver_cancer_treatment_{model_name.lower()}_model.pkl\"\n",
    "                joblib.dump(model, filename)\n",
    "                print(f\"âœ… {model_name} ëª¨ë¸ ì €ì¥: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ {model_name} ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"ì „ì²´ ë¶„ì„ ì‹¤í–‰ (ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ XAI í¬í•¨)\"\"\"\n",
    "        print(\"ğŸ¯ ê°„ì•” ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ëª¨ë¸ ì „ì²´ ë¶„ì„ ì‹œì‘ (XAI í¬í•¨)\")\n",
    "        \n",
    "        try:\n",
    "            # 1. ë°ì´í„° ë¡œë“œ\n",
    "            if not self.load_and_explore_data():\n",
    "                return False\n",
    "            \n",
    "            # 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "            if not self.preprocess_data():\n",
    "                return False\n",
    "            \n",
    "            # 3. íŠ¹ì„± ì¤€ë¹„\n",
    "            X, y_structured, y_duration, y_event, y_effectiveness, scaler, label_encoders = self.prepare_features()\n",
    "            \n",
    "            # 4. ë°ì´í„° ë¶„í• \n",
    "            (X_train, X_val, X_test, \n",
    "             y_train_struct, y_val_struct, y_test_struct,\n",
    "             y_train_dur, y_val_dur, y_test_dur,\n",
    "             y_train_event, y_val_event, y_test_event,\n",
    "             y_train_eff, y_val_eff, y_test_eff) = self.split_data(X, y_structured, y_duration, y_event, y_effectiveness)\n",
    "            \n",
    "            # 5. ëª¨ë¸ í›ˆë ¨\n",
    "            if not self.train_models(X_train, X_val, X_test,\n",
    "                                   y_train_struct, y_val_struct, y_test_struct,\n",
    "                                   y_train_dur, y_val_dur, y_test_dur,\n",
    "                                   y_train_event, y_val_event, y_test_event,\n",
    "                                   y_train_eff, y_val_eff, y_test_eff):\n",
    "                return False\n",
    "            \n",
    "            # 6. ëª¨ë¸ í‰ê°€\n",
    "            if not self.evaluate_models(X_train, X_val, X_test,\n",
    "                                       y_train_struct, y_val_struct, y_test_struct,\n",
    "                                       y_train_dur, y_val_dur, y_test_dur,\n",
    "                                       y_train_event, y_val_event, y_test_event,\n",
    "                                       y_train_eff, y_val_eff, y_test_eff):\n",
    "                return False\n",
    "            \n",
    "            # 7. XAI ì„¤ëª… ìƒì„±\n",
    "            self.explain_models(X_train, X_test)\n",
    "            \n",
    "            # 8. XAI ì‹œê°í™” ìƒì„±\n",
    "            self.generate_xai_visualizations(X_test)\n",
    "            \n",
    "            # 9. ì‹œê°í™” (XAI í¬í•¨)\n",
    "            if not self.plot_results(X_test, y_test_dur, y_test_event, y_test_eff):\n",
    "                return False\n",
    "            \n",
    "            # 10. ë³´ê³ ì„œ ìƒì„±\n",
    "            self.generate_report()\n",
    "            \n",
    "            # 11. ëª¨ë¸ ì €ì¥\n",
    "            self.save_models()\n",
    "            \n",
    "            print(\"\\nğŸ‰ ì „ì²´ ë¶„ì„ ì™„ë£Œ!\")\n",
    "            print(f\"â° ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    # ë°ì´í„° ê²½ë¡œ\n",
    "    data_path = r\"C:\\Users\\02\\Documents\\GDCdata_liver\\clinical_data_liver.csv\"\n",
    "    \n",
    "    # ë¶„ì„ ì‹¤í–‰\n",
    "    treatment_model = LiverCancerTreatmentEffectPredictor(data_path)\n",
    "    success = treatment_model.run_complete_analysis()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nâœ¨ ëª¨ë“  ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        print(\"ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:\")\n",
    "        print(\"   - liver_cancer_treatment_effect_prediction_with_xai.png (ì‹œê°í™” ê²°ê³¼)\")\n",
    "        print(\"   - liver_cancer_treatment_effect_prediction_report.txt (ë¶„ì„ ë³´ê³ ì„œ)\")\n",
    "        print(\"   - liver_cancer_treatment_*_model.pkl (í›ˆë ¨ëœ ëª¨ë¸ë“¤)\")\n",
    "        print(\"   - shap_*.png (SHAP ì„¤ëª…)\")\n",
    "        print(\"   - lime_*.png (LIME ì„¤ëª…)\")\n",
    "        print(\"\\nğŸ”¬ í¬í•¨ëœ ëª¨ë¸ë“¤:\")\n",
    "        print(\"   ìƒì¡´ ì˜ˆì¸¡: Random Survival Forest, Cox, GBSA\")\n",
    "        print(\"   ì¹˜ë£Œíš¨ê³¼ ë¶„ë¥˜: Random Forest, XGBoost, LightGBM\")\n",
    "        print(\"   ìƒì¡´ì‹œê°„ ì˜ˆì¸¡: Random Forest Regressor\")\n",
    "        print(\"   XAI: SHAP, LIME ì ìš©\")\n",
    "        print(\"\\nğŸ¯ ì„ìƒ í™œìš©:\")\n",
    "        print(\"   - ê°œë³„í™”ëœ ì¹˜ë£Œ ê³„íš ìˆ˜ë¦½\")\n",
    "        print(\"   - ì¹˜ë£Œ ë°˜ì‘ ì˜ˆì¸¡ ë° ëª¨ë‹ˆí„°ë§\")\n",
    "        print(\"   - ê³ ìœ„í—˜êµ° ì§‘ì¤‘ ê´€ë¦¬ ì „ëµ\")\n",
    "    else:\n",
    "        print(\"\\nâŒ ë¶„ì„ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e4a928",
   "metadata": {},
   "source": [
    "## LIME ê°œë³„ í™˜ì ì„¤ëª… (XGBoost ëª¨ë¸)\n",
    "\n",
    "- ì¹˜ë£Œ íš¨ê³¼ì— ì˜í–¥ì„ ë¯¸ì¹œ ìš”ì¸ë“¤:\n",
    "\n",
    "1) ì¹˜ë£Œ íš¨ê³¼ ì–‘í˜¸ ë°©í–¥ (ë…¹ìƒ‰):\n",
    "- **year_of_diagnosis â‰¤ -0.45**: ì§„ë‹¨ ì—°ë„ê°€ ì¹˜ë£Œ íš¨ê³¼ í–¥ìƒì— ê°€ì¥ í° ê¸°ì—¬ (0.15)\n",
    "- **tumor_grade â‰¤ -0.33**: ì¢…ì–‘ ë“±ê¸‰ì´ ë‚®ì„ìˆ˜ë¡ ì¹˜ë£Œ íš¨ê³¼ ì–‘í˜¸ (0.13)\n",
    "- **gender â‰¤ -1.44**: ì„±ë³„ ìš”ì¸ì´ ì¹˜ë£Œ íš¨ê³¼ì— ê¸ì •ì  ê¸°ì—¬ (0.05)\n",
    "\n",
    "2) ì¹˜ë£Œ íš¨ê³¼ ë¶ˆëŸ‰ ë°©í–¥ (ë¹¨ê°„ìƒ‰):\n",
    "- **-0.67 < ajcc_pathologic_n â‰¤ 1.50**: ë¦¼í”„ì ˆ ì „ì´ ìƒíƒœê°€ ì¹˜ë£Œ íš¨ê³¼ì— ë¶€ì •ì  ì˜í–¥ (-0.07)\n",
    "- **ishak_fibrosis_score â‰¤ -0.68**: ê°„ì„¬ìœ í™” ì ìˆ˜ê°€ ì¹˜ë£Œ íš¨ê³¼ì— ë¶€ì •ì  ì˜í–¥ (-0.05)\n",
    "\n",
    "## SHAP ì „ì—­ íŠ¹ì„± ì¤‘ìš”ë„ (LightGBM ëª¨ë¸)\n",
    "\n",
    "1) ê°€ì¥ ì¤‘ìš”í•œ ì¹˜ë£Œ íš¨ê³¼ ì˜ˆì¸¡ ì¸ìë“¤:\n",
    "1. **year_of_diagnosis** (1.5): ì§„ë‹¨ ì—°ë„ê°€ ì••ë„ì ìœ¼ë¡œ ê°€ì¥ ì¤‘ìš”í•œ ì¸ì\n",
    "2. **age_at_diagnosis** (0.5): ì§„ë‹¨ ì‹œ ì—°ë ¹\n",
    "3. **ishak_fibrosis_score** (0.5): ê°„ì„¬ìœ í™” ì •ë„\n",
    "4. **tumor_grade** (0.4): ì¢…ì–‘ ë“±ê¸‰\n",
    "5. **race** (0.3): ì¸ì¢…ì  ìš”ì¸\n",
    "\n",
    "## ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„\n",
    "\n",
    "1) ì„±ëŠ¥:\n",
    "- **ìµœê³  ì„±ëŠ¥ ëª¨ë¸**: XGBoost (í…ŒìŠ¤íŠ¸ ì •í™•ë„ 66.7%)\n",
    "- **ìƒì¡´ ì˜ˆì¸¡**: Cox ëª¨ë¸ (C-index 0.648)ì´ ê°€ì¥ ì•ˆì •ì \n",
    "- **ì¹˜ë£Œ íš¨ê³¼ ë¶„ë¥˜**: ëª¨ë“  ëª¨ë¸ì´ 60-67% ìˆ˜ì¤€ì˜ ì ì • ì„±ëŠ¥\n",
    "\n",
    "## ì„ìƒì  í•´ì„\n",
    "\n",
    "1) ì§„ë‹¨ ì—°ë„ì˜ ì••ë„ì  ì¤‘ìš”ì„±:\n",
    "- ì˜ë£Œ ê¸°ìˆ  ë°œì „, ì¹˜ë£Œë²• ê°œì„ , ì¡°ê¸° ì§„ë‹¨ ê¸°ë²• í–¥ìƒ ë“±ì´ ë³µí•©ì ìœ¼ë¡œ ì‘ìš©\n",
    "- ìµœê·¼ ì§„ë‹¨ë°›ì€ í™˜ìì¼ìˆ˜ë¡ ì¹˜ë£Œ íš¨ê³¼ê°€ ì–‘í˜¸í•  ê°€ëŠ¥ì„± ë†’ìŒ\n",
    "- ì´ëŠ” ê°„ì•” ì¹˜ë£Œì˜ ì§€ì†ì ì¸ ë°œì „ì„ ë°˜ì˜\n",
    "\n",
    "2) ì—°ë ¹ê³¼ ì¢…ì–‘ íŠ¹ì„±ì˜ ì—­í• :\n",
    "- ì Šì€ ì—°ë ¹ì—ì„œ ì¹˜ë£Œ ë°˜ì‘ì´ ë” ì¢‹ìŒ\n",
    "- ë‚®ì€ ì¢…ì–‘ ë“±ê¸‰(well-differentiated)ì—ì„œ ì¹˜ë£Œ íš¨ê³¼ ìš°ìˆ˜\n",
    "- ê°„ì„¬ìœ í™” ì •ë„ê°€ ì¹˜ë£Œ ê²°ê³¼ì— ì¤‘ìš”í•œ ì˜í–¥\n",
    "\n",
    "3) ê°œë³„í™”ëœ ì¹˜ë£Œ ì „ëµ:\n",
    "- ì§„ë‹¨ ì—°ë„, ì—°ë ¹, ì¢…ì–‘ ë“±ê¸‰ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•œ ì¹˜ë£Œ ê³„íš ìˆ˜ë¦½ í•„ìš”\n",
    "- ê³ ë ¹ í™˜ìë‚˜ ê³ ë“±ê¸‰ ì¢…ì–‘ í™˜ìì—ì„œëŠ” ë” ì ê·¹ì ì¸ ì¹˜ë£Œ ì ‘ê·¼ ê³ ë ¤\n",
    "- ê°„ì„¬ìœ í™”ê°€ ì‹¬í•œ í™˜ìì—ì„œëŠ” ê°„ê¸°ëŠ¥ ë³´ì¡´ì„ ìš°ì„ í•œ ì¹˜ë£Œ ì „ëµ\n",
    "\n",
    "## XAIì˜ ì„ìƒì  ê°€ì¹˜\n",
    "\n",
    "1) ê°œë³„ í™˜ì ë§ì¶¤ ì„¤ëª…:\n",
    "- LIME ê²°ê³¼ë¥¼ í†µí•´ ê° í™˜ìë³„ë¡œ ì–´ë–¤ ì¸ìê°€ ì¹˜ë£Œ íš¨ê³¼ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ì§€ ëª…í™•íˆ íŒŒì•…\n",
    "- ì˜ë£Œì§„ì´ í•´ë‹¹ ì¸ìë“¤ì„ ì§‘ì¤‘ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” ê·¼ê±° ì œê³µ\n",
    "\n",
    "2) ì¹˜ë£Œ ì˜ì‚¬ê²°ì • ì§€ì›:\n",
    "- ì§„ë‹¨ ì—°ë„ì™€ í™˜ì íŠ¹ì„±ì„ ê³ ë ¤í•œ ê°œë³„í™”ëœ ì¹˜ë£Œ ê°•ë„ ê²°ì •\n",
    "- ì¹˜ë£Œ ë°˜ì‘ ì˜ˆì¸¡ì„ í†µí•œ ì¡°ê¸° ì¹˜ë£Œ ì „ëµ ìˆ˜ì •\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
